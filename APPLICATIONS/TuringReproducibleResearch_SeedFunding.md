# Seed Funding Application

## Research description

### Description and alignment with strategic aims
*(1000 words)*

**=== Potential shorter introduction from Martin (feel free to cherry pick / completely ignore as you see fit) ===**

***Introduction***

***We would like to position The Alan Turing Institute as a world leader for reproducible research*** by embedding a culture of "reproducible by default" at the institute and providing training and tools to make reproducible research "too easy not to do".

Reproducibility ensures that the wider academic, industry and governmental communities we operate in can easily validate, replicate and build on the work we produce. This will help us extend the Turing's impact beyond the immediate outputs of the institute itself, providing a "force multiplier" effect on the progress of Data Science in the UK and beyond.

We want the research outputs of the Turing to be seen as coming with a "quality seal of approval" that means the communities we operate in trust our research and want to work with our people. We want "Turing quality" to be a synonym for high-quality research and high-quality people.

With an increasing focus on the scientific "reproducibility crisis" by the [academic](http://www.nature.com/news/1-500-scientists-lift-the-lid-on-reproducibility-1.19970) and [popular](http://www.bbc.co.uk/news/science-environment-39054778) press, as well as by [government](https://www.parliament.uk/business/committees/committees-a-z/commons-select/science-and-technology-committee/inquiries/parliament-2015/inquiry6/),  ensuring that the Turing takes a leadership role in making research reproducible is more important than ever.

**=== End of Martin's potential alternative introduction ===**

***Introduction***

In 2015, the [Reproducibility Project: Psychology](http://dx.doi.org/10.1126/science.aac4716) by the [Center for Open Science](https://cos.io/) reported that 60% of psychology studies could not be reproduced. That is, when another group of scientists followed the same methods as in the originally published paper in a new sample of participants, they got a different answer. The problem is not limited to psychology. Early results from the [Reproducibility Project: Cancer Biology](https://elife.elifesciences.org/collections/reproducibility-project-cancer-biology) are not promising and we are no closer than we were in 2005 to disproving John Ioannidis' claim that "[Most published research findings are false](http://dx.doi.org/10.1371/journal.pmed.0020124)".

These publications and the headlines about the scientific "[reproducibility crisis](http://www.nature.com/news/1-500-scientists-lift-the-lid-on-reproducibility-1.19970)" across international media outlets threw into sharp relief a key aspect of the status quo in scientific research: *we simply do not know how much to trust current published scientific findings*. In fact, the House of Commons Science and Technology Committee is leading an inquiry into [research integrity in the UK](https://www.parliament.uk/business/committees/committees-a-z/commons-select/science-and-technology-committee/inquiries/parliament-2015/inquiry6/). Readers and peer reviewers alike are unable to see the underlying data or the steps that were taken to analyse it. This slows down the research process by making it harder for others to build on published findings, and - even worse - there can be little mistakes that lead to [great big errors](http://www.newyorker.com/news/john-cassidy/the-reinhart-and-rogoff-controversy-a-summing-up) in interpretation.

In order to investigate whether a published finding can replicate in a repetition of the same study (as the Center for Open Science teams were investigating) it is necessary that every step of the original work is reproducible. It is in fact a tenant of the [scientific method](https://en.wikipedia.org/wiki/Scientific_method) that evidence should be provided for any given result. ***We would like to position the Alan Turing Institute as a world leader for reproducible research*** by making it easy for all members of the Institute to share their code and data (where ethically possible) such that any reader of their published research can verify their findings. We will empower data scientists around the world to generate research findings that can be generalised by policy makers to affect change at a global scale.


***Accessible Data***

We will ensure that Turing researchers who have spent a long time collecting and curating datasets are able to make them available to others in the Institute as easily as possible. Specifically, we will support them by helping to build up documentation and providing dissemination channels within the Turing Institute.

Turing researchers will also have the option to share their datasets publically. We plan to particularly support these members by providing clear guidance on ethical constraints and best practises regarding persistent data archiving. We will make it easy for data curators to receive citations for their hard work, for example by assigning [digital online identifiers](https://www.datacite.org/), or by publishing [data description papers](http://www.nature.com/sdata/). We will work with the Turing Institute communications team to ensure that the public datasets are promoted widely to members of the global data science community.

Sensitive data will be hosted within the Turing under customisable levels of password control. For example, it may be open to all Turing members, open to Turing members on a specific collaboration list or open to members given a data access agreement.

Importantly, the documentation will be standardised and easy to follow. If [data management plans](http://www.data.cam.ac.uk/data-management-guide/creating-your-data/data-management-plan) are adopted and followed from the beginning of the project, they not only ensure that the database is an excellent resource for future research, they also ensure that the research team are more efficient in their analysis process.

***Open Source Code***

In order to reproduce published findings it is necessary to have the exact steps the researchers undertook in generating their results. We will support all members of the Turing Institute in sharing the code they write with readers of their published results. As a minimum we would like to ensure that publications from the Turing can be verified by any independent researcher.

Beyond reproducible research, sharing analysis code allows members of the Turing Institute to "stand on the shoulders of giants" and benefit from the expertise of their colleagues. We will ensure that Turing members are working efficiently through two key avenues. The first, as with accessible data, we will help to provide documentation and dissemination channels to clearly communicate what effort has been undertaken to date.

Secondly, we will support members of the Turing Institute by harnessing the power and expertise of the research software engineering team. They will work with researchers to document and fully develop code to a higher standard than is currently required of academic researchers. For example, we will package the dependencies that are required to run the analysis code to remove as many installation challenges as possible. Members of the Turing Institute and the data science community at large will benefit from reliable, tested, version controlled analysis code.

***Customisable pathways to reproducibility***

We want to provide three pathways for reproducible research to Turing members:

1. **Open from the start**: All work is conducted in a public GitHub repository from the beginning meaning that anyone can follow the project and potentially contribute.
2. **Private then public** (recommended default): The work is conducted in a private GitHub repository that is switched to public on publication of a related paper. All versions of the code are therefore made available but the development is kept within the Turing Institute.
3. **Private then clean public repository**: The work is developed in a private GitHub repository and on publication a new "clean" public repository is created and shared. All code is available but the (sometimes messy) history of the project stays private.

It will be possible to customise these pathways, for example with separate policies for sharing of data and code. In particular there may be ethical constraints on data access, in which case we will maintain a list of verified collaborators for a managed access database.

***Training***

By design, the Turing Institute comprises researchers of different backgrounds and expertise. An often cited reason for not ensuring that research is reproducible is the lack of training provided in the tools. We will run brief trainings and provide getting-started resources for version control with git and GitHub, code testing, intro to coding in Python, R and Unix, along with "demystify" sessions around software engineering. We will ensure that all members of the Turing Institute have good onboarding documentation and will provide office hours to provide invaluable in-person support.


***Turing Strategic Aims***

This proposal aligns with the **Systems and Platforms** focus of the Turing Institute. We will provide support, training and guidance to ensure that all members of the Turing are able, *with ease*, to share their work and allow others to quickly verify their work.

This Reproducible Research proposal benefits every one of the six priority sectors for the Turing Institute. Awareness of the "reproducibility crisis" is very high in the biomedical sciences and social sciences, but providing supporting evidence for our work is necessary in all fields of data science.


### Outputs and Impact

*(250 words)*

The *Reproducible Research at the Turing* seed funding will provide the following outputs:

1. Documentation, research software engineer support and expert guidance to ensure any member of the Turing Institute who would like to make their work reproducible is able to do so.
2. A curated database of resources within the Turing Institute including available data sets, open source code and training materials.
3. An onboarding program of resources and in person trainings to ensure all members of the Turing Institute are able to start work efficiently on their arrival.

The *Reproducible Research at the Turing* seed funding will provide the following impact:

* Individual researchers at the Turing Institute will benefit immediately as they will be able to access resources quickly and receive support in disseminating their work.
* The partner universities will benefit as their associated publications will be reproducible, which is both faster and more efficient that "reinventing the wheel" each time, and allows submission to higher impact journals as TOP guidelines are adopted more widely.
* The Turing will benefit by a strengthening of their brand as being world leaders in data science. We will build a culture of reproducibility within the Institute which will ensure all readers will trust output from the Alan Turing Institute. They will also receive more citations from the data and software papers that accompany traditional academic articles.
* The wider data science community will benefit from the tools and open data sets provide by members of the Turing Institute. Furthermore, they will have concrete examples of how to ensure their own work is reproducible, improving the reliability of the field as a whole.


## Resources, Budget and Planning

### Request

* 39 days Martin O'Reilly's time: £15,000
* 6 months full time or 12 months part time reproducible research liaison officer appointment: £20,000

### Justification

The reproducible research liaison officer is costed at an annual salary of £30,000 with on-costs of £8,000. We anticipate that the work outlined will take around 6 months full time equivalent and have outlined a timeline accordingly. However, it may be challenging to recruit a qualified candidate for only 6 months and therefore we have kept open the possibility of bringing someone in at half time for 12 months.

Dr O'Reilly is costed as dedicating 1.5 days per week to advancing reproducible research at the Turing Institute for 6 months at £450/day.

### Project Plan

*(500 words)*

*Note: It is not necessary to complete all sections of the project plan in the bullet points outlined on the application form. I've dropped "project plan" and put that information into the timeline and milestones sections.*

**Project plan**

*Reproducible research liaison officer*

We will recruit and hire for either 6 months full time, or 12 months part time, a reproducible research liaison officer. She is likely to have a doctoral degree in a computational field to ensure that she is able to easily communicate with Turing researchers about their needs and current working practises. It is necessary that she has very strong communication skills and will be responsible for supporting the creation and maintenance of documentation of data and software code, along with writing lay summaries to promote reproducible research from Turing members. The reproducible research liaison officer will undertake the requirement gathering exercises outlined below, and report the Dr Kirstie Whitaker.

*Requirement Gathering*

The most important step in our plan is to see what already exists, what needs to be curated and if there are already tools that would do the job. We will focus on collecting information around:

* What tools already exist?
* What are researchers in the Turing Institute using?
* What resources would best serve Turing Institute researchers?
* Can we contribute to existing projects to make them even better?
* Do we need to create any new software?

**Timeline**:

* **May**: Initial survey of Turing researchers to assess their needs & what resources are already available. Open recruitment for reproducible research liaison officer.
* **June**: Interns arrive and contribute to onboarding documentation as they settle into the Turing.
* **July & August**: Liaison officer joins Turing Institute. She formalises documentation and scales information. Receives feedback from interns and current Turing researchers willing to act as "early adopters".
* **September - December**: First full run of onboarding and training with new graduate students. Continuous refinement through first term.

**Milestones**:

* **June**: Interns arrive and give feedback on content of onboarding documentation as they settle into the Turing.
* **July**: Reproducible research liaison officer starts 6 month position.
* **September**: First complete draft of onboarding documentation shared with incoming PhD students.
* **December**: Refined onboarding documentation completed.
